apiVersion: v1
kind: Pod
metadata:
  name: cuda-smi-test
spec:
  # Ensures the pod is only scheduled on a node with the GPU label
  nodeSelector:
    node-role.kubernetes.io/gpu: "true"
  restartPolicy: OnFailure
  containers:
    - name: cuda-test-container
      image: "nvidia/cuda:12.8.1-devel-ubuntu22.04"
      command: ["nvidia-smi"]
      resources:
        requests:
          cpu: "250m"
          memory: "512Mi"
        limits:
          nvidia.com/gpu: "1"
          cpu: "1"
          memory: "1Gi"
